{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Digital Divide\n",
    "### Data Analysis\n",
    "\n",
    "#### Based on PPIC's Just the Facts report [\"California's Digital Divide\"](https://www.ppic.org/publication/californias-digital-divide/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question(s):\n",
    "1. What share households with school-age children in X state have access to high-speed internet? \n",
    "2. Does this number vary across demographic groups? (in this case race/ethnicity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "* Use our `working-data dataset` (created in [Data_Prep notebook](00_DigitalDivide_Data_Prep.ipynb) notebook) to answer our research questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context:\n",
    "* Write yourself a description of the context: Include a description of the data (_data set contains X state's data for YYYY year_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Set up your working environment.\n",
    "\n",
    "Import all necessary libraries and create `Path`s to your data directories. This ensures reproducibility across file systems (windows uses `\\` instead of `/`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need \n",
    "1. `pandas` to work with the data.\n",
    "2. `pathlib`, and more specifically its `Path` object, to work with paths. This will ensure our code works in both Windows (which uses `\\` in its file paths) and MacOS/Linux (which uses `/`).\n",
    "3. `datetime` - tip: There are version control systems for data but tagging your data files with the date is not a bad first step if you're getting started.\n",
    "4. `tree` - to display a directory's tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27-Apr-19\n"
     ]
    }
   ],
   "source": [
    "# setting up working environment\n",
    "import _____ as pd\n",
    "from _____ import Path\n",
    "from tools import _________\n",
    "from ______ import _______ as dt\n",
    "today = dt.______()._______(\"%_-%_-%_\")\n",
    "\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data folder and paths\n",
    "RAW_DATA_PATH = ____(\"../data/raw/\")\n",
    "XXXX_XXXXX_XXXX = ____(\"../data/interim/\")\n",
    "YYYY_YYYYY_YYYY = ____(\"../data/processed/\")\n",
    "ZZZZ_ZZZZZ_ZZZZ = ____(\"../data/final/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree(INTERIM_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata(INTERIM_DATA_PATH / f'working_data-{today}.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44816, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data._______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>serial</th>\n",
       "      <th>hhwt</th>\n",
       "      <th>stateicp</th>\n",
       "      <th>countyfip</th>\n",
       "      <th>cinethh</th>\n",
       "      <th>cihispeed</th>\n",
       "      <th>pernum</th>\n",
       "      <th>perwt</th>\n",
       "      <th>relate</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>hispan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>953662</td>\n",
       "      <td>57</td>\n",
       "      <td>ohio</td>\n",
       "      <td>0</td>\n",
       "      <td>yes, with a subscription to an internet service</td>\n",
       "      <td>yes (cable modem, fiber optic or dsl service)</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>head/householder</td>\n",
       "      <td>female</td>\n",
       "      <td>48</td>\n",
       "      <td>white</td>\n",
       "      <td>not hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>953662</td>\n",
       "      <td>57</td>\n",
       "      <td>ohio</td>\n",
       "      <td>0</td>\n",
       "      <td>yes, with a subscription to an internet service</td>\n",
       "      <td>yes (cable modem, fiber optic or dsl service)</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>child</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>white</td>\n",
       "      <td>not hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>953662</td>\n",
       "      <td>57</td>\n",
       "      <td>ohio</td>\n",
       "      <td>0</td>\n",
       "      <td>yes, with a subscription to an internet service</td>\n",
       "      <td>yes (cable modem, fiber optic or dsl service)</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>child</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>white</td>\n",
       "      <td>not hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>953668</td>\n",
       "      <td>140</td>\n",
       "      <td>ohio</td>\n",
       "      <td>61</td>\n",
       "      <td>yes, with a subscription to an internet service</td>\n",
       "      <td>yes (cable modem, fiber optic or dsl service)</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>head/householder</td>\n",
       "      <td>male</td>\n",
       "      <td>28</td>\n",
       "      <td>black/african american/negro</td>\n",
       "      <td>not hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>953668</td>\n",
       "      <td>140</td>\n",
       "      <td>ohio</td>\n",
       "      <td>61</td>\n",
       "      <td>yes, with a subscription to an internet service</td>\n",
       "      <td>yes (cable modem, fiber optic or dsl service)</td>\n",
       "      <td>2</td>\n",
       "      <td>192</td>\n",
       "      <td>sibling</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>black/african american/negro</td>\n",
       "      <td>not hispanic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  serial  hhwt stateicp  countyfip  \\\n",
       "0  2017  953662    57     ohio          0   \n",
       "1  2017  953662    57     ohio          0   \n",
       "2  2017  953662    57     ohio          0   \n",
       "3  2017  953668   140     ohio         61   \n",
       "4  2017  953668   140     ohio         61   \n",
       "\n",
       "                                           cinethh  \\\n",
       "0  yes, with a subscription to an internet service   \n",
       "1  yes, with a subscription to an internet service   \n",
       "2  yes, with a subscription to an internet service   \n",
       "3  yes, with a subscription to an internet service   \n",
       "4  yes, with a subscription to an internet service   \n",
       "\n",
       "                                       cihispeed  pernum  perwt  \\\n",
       "0  yes (cable modem, fiber optic or dsl service)       1     58   \n",
       "1  yes (cable modem, fiber optic or dsl service)       2     62   \n",
       "2  yes (cable modem, fiber optic or dsl service)       3     78   \n",
       "3  yes (cable modem, fiber optic or dsl service)       1    140   \n",
       "4  yes (cable modem, fiber optic or dsl service)       2    192   \n",
       "\n",
       "             relate     sex age                          race        hispan  \n",
       "0  head/householder  female  48                         white  not hispanic  \n",
       "1             child    male  20                         white  not hispanic  \n",
       "2             child  female   9                         white  not hispanic  \n",
       "3  head/householder    male  28  black/african american/negro  not hispanic  \n",
       "4           sibling  female  16  black/african american/negro  not hispanic  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data._______()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 44816 entries, 0 to 44815\n",
      "Data columns (total 14 columns):\n",
      "year         44816 non-null category\n",
      "serial       44816 non-null int32\n",
      "hhwt         44816 non-null int16\n",
      "stateicp     44816 non-null category\n",
      "countyfip    44816 non-null int16\n",
      "cinethh      44816 non-null category\n",
      "cihispeed    44816 non-null category\n",
      "pernum       44816 non-null int8\n",
      "perwt        44816 non-null int16\n",
      "relate       44816 non-null category\n",
      "sex          44816 non-null category\n",
      "age          44816 non-null category\n",
      "race         44816 non-null category\n",
      "hispan       44816 non-null category\n",
      "dtypes: category(9), int16(3), int32(1), int8(1)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "data._____()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our **unit of observation** is still a (weighted) person but we're interested in **household-level** data. \n",
    "\n",
    "From IPUMS docs:\n",
    ">HHWT indicates how many households in the U.S. population are represented by a given household in an IPUMS sample. <br><br>\n",
    ">It is generally a good idea to use HHWT when conducting a household-level analysis of any IPUMS sample. The use of HHWT is optional when analyzing one of the \"flat\" or unweighted IPUMS samples. Flat IPUMS samples include the 1% samples from 1850-1930, all samples from 1960, 1970, and 1980, the 1% unweighted samples from 1990 and 2000, the 10% 2010 sample, and any of the full count 100% census datasets. HHWT must be used to obtain nationally representative statistics for household-level analyses of any sample other than those.<br><br>\n",
    ">**Users should also be sure to select one person (e.g., PERNUM = 1) to represent the entire household.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Drop all observations were `pernum` doesn't equal 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pernum = (________ _= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[mask_pernum].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your data to an appropriately named variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_households = ____[_________]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Familiarize yourself with your variables of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From IPUMS [docs](https://usa.ipums.org/usa-action/variables/CINETHH#description_section):\n",
    "\n",
    ">CINETHH reports whether any member of the household accesses the Internet. Here, \"access\" refers to whether or not someone in the household uses or connects to the Internet, regardless of whether or not they pay for the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the value_counts for your cinethh series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From IPUMS [docs](https://usa.ipums.org/usa-action/variables/CIHISPEED#description_section):\n",
    ">CIHISPEED reports whether the respondent or any member of their household subscribed to the Internet using broadband (high speed) Internet service such as cable, fiber optic, or DSL service. <br><br>\n",
    ">User Note: The ACS 2016 introduced changes to the questions regarding computer use and Internet access. See the comparability section and questionnaire text for more information. Additional information provided by the Census Bureau regarding these question alterations are available in the report: ACS Content Test Shows Need to Update Terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the value_counts for your cihispeed series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_quick tip_ `.value_counts()` _has a_ `normalize` _parameter:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return a Series containing counts of unique values.\n",
       "\n",
       "The resulting object will be in descending order so that the\n",
       "first element is the most frequently-occurring element.\n",
       "Excludes NA values by default.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "normalize : boolean, default False\n",
       "    If True then the object returned will contain the relative\n",
       "    frequencies of the unique values.\n",
       "sort : boolean, default True\n",
       "    Sort by values.\n",
       "ascending : boolean, default False\n",
       "    Sort in ascending order.\n",
       "bins : integer, optional\n",
       "    Rather than count values, group them into half-open bins,\n",
       "    a convenience for ``pd.cut``, only works with numeric data.\n",
       "dropna : boolean, default True\n",
       "    Don't include counts of NaN.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "counts : Series\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Series.count: Number of non-NA elements in a Series.\n",
       "DataFrame.count: Number of non-NA elements in a DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> index = pd.Index([3, 1, 2, 3, 4, np.nan])\n",
       ">>> index.value_counts()\n",
       "3.0    2\n",
       "4.0    1\n",
       "2.0    1\n",
       "1.0    1\n",
       "dtype: int64\n",
       "\n",
       "With `normalize` set to `True`, returns the relative frequency by\n",
       "dividing all values by the sum of values.\n",
       "\n",
       ">>> s = pd.Series([3, 1, 2, 3, 4, np.nan])\n",
       ">>> s.value_counts(normalize=True)\n",
       "3.0    0.4\n",
       "4.0    0.2\n",
       "2.0    0.2\n",
       "1.0    0.2\n",
       "dtype: float64\n",
       "\n",
       "**bins**\n",
       "\n",
       "Bins can be useful for going from a continuous variable to a\n",
       "categorical variable; instead of counting unique\n",
       "apparitions of values, divide the index in the specified\n",
       "number of half-open bins.\n",
       "\n",
       ">>> s.value_counts(bins=3)\n",
       "(2.0, 3.0]      2\n",
       "(0.996, 2.0]    2\n",
       "(3.0, 4.0]      1\n",
       "dtype: int64\n",
       "\n",
       "**dropna**\n",
       "\n",
       "With `dropna` set to `False` we can also see NaN index values.\n",
       "\n",
       ">>> s.value_counts(dropna=False)\n",
       "3.0    2\n",
       "NaN    1\n",
       "4.0    1\n",
       "2.0    1\n",
       "1.0    1\n",
       "dtype: int64\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/pycon/lib/python3.7/site-packages/pandas/core/base.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series.value_counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it on your cinethh series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on cihispeed \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be the end of our analysis if we weren't working with **weighted** data. **Weighted** data means each of our observations represent more than one person or household.\n",
    "\n",
    "`perwt` = \"Person's weight\"\n",
    "\n",
    "`hhwt` = \"Household's weight\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.value_counts(normalize=True)` counts the number of **observations** for each of a series' values and then divides it by the total count. If each of our observations was 1 person/household, we would have the answer already. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need to do is **aggregate**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Grouping and aggregating data\n",
    "\n",
    "The mechanics are kind of the same: \n",
    "1. Count the number of observations each that match each of the values in a series.\n",
    "2. Add up **not the number of observations** but the weight of each observation.\n",
    "3. Divide by the total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1: Group your data by their corresponding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x114b5a710>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_households.groupby(\"_________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [docs](http://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html):\n",
    "\n",
    ">A groupby operation involves some combination of splitting the\n",
    "object, __applying a function__, and combining the results. This can be\n",
    "used to group large amounts of data and compute operations on these\n",
    "groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're missing the **applying a function** part of it.\n",
    "\n",
    "Try the following:\n",
    "```python\n",
    "state_households.groupby(\"countyfip\").sum()\n",
    "```\n",
    "\n",
    "you can pass _almost_ any function to this. \n",
    "\n",
    "Try `.mean()`, `.max()`, `.min()`, `.std()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select columns just like you would any other regular dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_households.groupby(\"________\")['hhwt']._____()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_households = state_households.groupby(\"cihispeed\")['hhwt'].sum()[2]\n",
    "_state = state_households['statefip'].unique()[0]\n",
    "print(f\"\"\"\n",
    "We can see now {n_households:,} households in {_state} have access to high-speed internet. But, out of how many?\n",
    "\n",
    "To make this easier to follow, let's save our results to a variable:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households_with_highspeed_access = ____________._____(\"_____\")[\"____\"].___()\n",
    "\n",
    "households_with_highspeed_access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like any regular `pandas.Series`, how do we find the total `.sum()` of a series elements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![math](../../static/math.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's our denominator! \n",
    "\n",
    "![nice](../../static/nooice.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you _apply_ and operation to a `pandas.Series` it _maps_ to each of its elements.\n",
    "\n",
    "Try the following:\n",
    "```python\n",
    "households_with_highspeed_access * 1_000_000\n",
    "```\n",
    "\n",
    "```python\n",
    "households_with_highspeed_access + 1_000_000\n",
    "```\n",
    "\n",
    "```python\n",
    "households_with_highspeed_access / 1_000_000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the denominator of our equation (how many households total in X state), how would you find each of the 3 values in your `households_with_highspeed_access` share of the total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 of analysis: Creating derived variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have answered **Research Question 1**, we can move on to Q2: \n",
    ">_Does this number vary across demographic groups? (in this case race/ethnicity)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas `.groupby()` function can take a list of columns by which to group by \n",
    "\n",
    "Try the following:\n",
    "```python\n",
    "state_households.groupby(['race', 'cihispeed'])[['hhwt']].sum()\n",
    "```\n",
    "\n",
    "_Notice that I'm passing_ `[['hhwt']]` _(a 1-element list) and not just_ `['hhwt']` _try both yourself and let's discuss what's the difference._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Define your groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas' `.loc` indexer serves not only to slice dataframes but also to assign new values to certain slices of dataframes.\n",
    "\n",
    "For example,\n",
    "```python\n",
    "mask_madeup_data = (data['column_1'] == 'no answer')\n",
    "data.loc[mask_madeup_data, 'new_column'] = 'this row did not answer'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above grabs all the rows that satisfy the condition and then looks at `'new_column'`, if it doesn't exist, it'll create it for you and assign the value `'this row did not answer'` to all the rows that match the condition. The rest will be filled with null values (NaNs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Let's create our masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_latino = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_white = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_black = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_______ = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_______ = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_______ =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the values to a new column `'racen'` for Race/Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_households.loc[mask_latino, 'racen'] = 'Latino'\n",
    "state_households.loc[mask_white, 'racen'] = 'White'\n",
    "state_households.loc[mask_black, 'racen'] = 'Black/African-American'\n",
    "state_households.loc[mask_______, 'racen'] = '_______'\n",
    "state_households.loc[mask_______, 'racen'] = '_______'\n",
    "state_households.loc[mask_______, 'racen'] = '_______'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking your results.\n",
    "\n",
    "Under your new logic, all `race` values should fit into `racen` values so there should not be any null values, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas `.isna()` returns a series of either True or False for each value of a series depending on whether or not it is Null. \n",
    "\n",
    "AND\n",
    "\n",
    "in python, True = 1 and False = 0. \n",
    "\n",
    "What do you think would happen if you as for the `.sum()` total of a `pandas.Series` of booleans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple ways of grouping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have derived a working variable for race/ethnicity you can aggregate your data to answer **RQ2**. In pandas, there are many ways to do this, some of them are:\n",
    "1. `.groupby()` like we've done so far.\n",
    "2. `.pivot_table()`\n",
    "3. `pd.crosstabs()` <- this one is a `pandas` method, not a DataFrame method. More later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_households.groupby(['racen', '______'])[['______']]._____()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save that to an appropriately named variable since we'll be using it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cihispeed_by_racen = state_households.groupby(['racen', '______'])[['______']]._____()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this grouped dataframe has the total number of households in each of these racen-cihispeed groups. \n",
    "\n",
    "We need the share of cihispeed values by racen group. \n",
    "\n",
    "In our equation,\n",
    "\n",
    "$$ \\frac{households\\ with\\ high\\ speed\\ internet}{total\\ households\\ in\\ racen\\ group}$$\n",
    "\n",
    "We need to find the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide your racen-cihispeed by denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to appropriately named variable\n",
    "shares_cihispeed_by_racen = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a multi-level index dataframe and there are a few ways to slice it. Let's try 3:\n",
    "1. a classsic `.loc` slice\n",
    "2. a cross-section (`.xs()`)\n",
    "3. the `.reset_index()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classic `.loc`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares_cihispeed_by_racen.loc[INDEX_SLICER, COLUMNS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mshares_cihispeed_by_racen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return cross-section from the Series/DataFrame.\n",
       "\n",
       "This method takes a `key` argument to select data at a particular\n",
       "level of a MultiIndex.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "key : label or tuple of label\n",
       "    Label contained in the index, or partially in a MultiIndex.\n",
       "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
       "    Axis to retrieve cross-section on.\n",
       "level : object, defaults to first n levels (n=1 or len(key))\n",
       "    In case of a key partially contained in a MultiIndex, indicate\n",
       "    which levels are used. Levels can be referred by label or position.\n",
       "drop_level : bool, default True\n",
       "    If False, returns object with same levels as self.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "Series or DataFrame\n",
       "    Cross-section from the original Series or DataFrame\n",
       "    corresponding to the selected index levels.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.loc : Access a group of rows and columns\n",
       "    by label(s) or a boolean array.\n",
       "DataFrame.iloc : Purely integer-location based indexing\n",
       "    for selection by position.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "`xs` can not be used to set values.\n",
       "\n",
       "MultiIndex Slicers is a generic way to get/set values on\n",
       "any level or levels.\n",
       "It is a superset of `xs` functionality, see\n",
       ":ref:`MultiIndex Slicers <advanced.mi_slicers>`.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> d = {'num_legs': [4, 4, 2, 2],\n",
       "...      'num_wings': [0, 0, 2, 2],\n",
       "...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
       "...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
       "...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
       ">>> df = pd.DataFrame(data=d)\n",
       ">>> df = df.set_index(['class', 'animal', 'locomotion'])\n",
       ">>> df\n",
       "                           num_legs  num_wings\n",
       "class  animal  locomotion\n",
       "mammal cat     walks              4          0\n",
       "       dog     walks              4          0\n",
       "       bat     flies              2          2\n",
       "bird   penguin walks              2          2\n",
       "\n",
       "Get values at specified index\n",
       "\n",
       ">>> df.xs('mammal')\n",
       "                   num_legs  num_wings\n",
       "animal locomotion\n",
       "cat    walks              4          0\n",
       "dog    walks              4          0\n",
       "bat    flies              2          2\n",
       "\n",
       "Get values at several indexes\n",
       "\n",
       ">>> df.xs(('mammal', 'dog'))\n",
       "            num_legs  num_wings\n",
       "locomotion\n",
       "walks              4          0\n",
       "\n",
       "Get values at specified index and level\n",
       "\n",
       ">>> df.xs('cat', level=1)\n",
       "                   num_legs  num_wings\n",
       "class  locomotion\n",
       "mammal walks              4          0\n",
       "\n",
       "Get values at several indexes and levels\n",
       "\n",
       ">>> df.xs(('bird', 'walks'),\n",
       "...       level=[0, 'locomotion'])\n",
       "         num_legs  num_wings\n",
       "animal\n",
       "penguin         2          2\n",
       "\n",
       "Get values at specified column and axis\n",
       "\n",
       ">>> df.xs('num_wings', axis=1)\n",
       "class   animal   locomotion\n",
       "mammal  cat      walks         0\n",
       "        dog      walks         0\n",
       "        bat      flies         2\n",
       "bird    penguin  walks         2\n",
       "Name: num_wings, dtype: int64\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/pycon/lib/python3.7/site-packages/pandas/core/generic.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shares_cihispeed_by_racen.xs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares_cihispeed_by_racen.xs(key = '________', level = _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`.reset_index()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to slice a multi-level index dataframe is to make it a not-multi-level index dataframe. To do that you need to _reset_ its index. After that, we can slice it how we've been slicing our dataframes previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__________ = ____________._________()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_yes_cihispeed = (_____________ = '___________')\n",
    "_______[mask_yes_cihispeed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second method of aggregating our data is `.pivot_table()`s.\n",
    "\n",
    "If you've worked with Excel, you might already be familiar with what a pivot table is.\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Pivot_table):\n",
    ">A pivot table is a table of statistics that summarizes the data of a more extensive table (such as from a database, spreadsheet, or business intelligence program). This summary might include sums, averages, or other statistics, which the pivot table groups together in a meaningful way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mstate_households\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maggfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmargins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmargins_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'All'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Create a spreadsheet-style pivot table as a DataFrame. The levels in\n",
       "the pivot table will be stored in MultiIndex objects (hierarchical\n",
       "indexes) on the index and columns of the result DataFrame.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "values : column to aggregate, optional\n",
       "index : column, Grouper, array, or list of the previous\n",
       "    If an array is passed, it must be the same length as the data. The\n",
       "    list can contain any of the other types (except list).\n",
       "    Keys to group by on the pivot table index.  If an array is passed,\n",
       "    it is being used as the same manner as column values.\n",
       "columns : column, Grouper, array, or list of the previous\n",
       "    If an array is passed, it must be the same length as the data. The\n",
       "    list can contain any of the other types (except list).\n",
       "    Keys to group by on the pivot table column.  If an array is passed,\n",
       "    it is being used as the same manner as column values.\n",
       "aggfunc : function, list of functions, dict, default numpy.mean\n",
       "    If list of functions passed, the resulting pivot table will have\n",
       "    hierarchical columns whose top level are the function names\n",
       "    (inferred from the function objects themselves)\n",
       "    If dict is passed, the key is column to aggregate and value\n",
       "    is function or list of functions\n",
       "fill_value : scalar, default None\n",
       "    Value to replace missing values with\n",
       "margins : boolean, default False\n",
       "    Add all row / columns (e.g. for subtotal / grand totals)\n",
       "dropna : boolean, default True\n",
       "    Do not include columns whose entries are all NaN\n",
       "margins_name : string, default 'All'\n",
       "    Name of the row / column that will contain the totals\n",
       "    when margins is True.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "table : DataFrame\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.pivot : Pivot without aggregation that can handle\n",
       "    non-numeric data.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
       "...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
       "...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
       "...                          \"one\", \"one\", \"two\", \"two\"],\n",
       "...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
       "...                          \"small\", \"large\", \"small\", \"small\",\n",
       "...                          \"large\"],\n",
       "...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
       "...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
       ">>> df\n",
       "     A    B      C  D  E\n",
       "0  foo  one  small  1  2\n",
       "1  foo  one  large  2  4\n",
       "2  foo  one  large  2  5\n",
       "3  foo  two  small  3  5\n",
       "4  foo  two  small  3  6\n",
       "5  bar  one  large  4  6\n",
       "6  bar  one  small  5  8\n",
       "7  bar  two  small  6  9\n",
       "8  bar  two  large  7  9\n",
       "\n",
       "This first example aggregates values by taking the sum.\n",
       "\n",
       ">>> table = pivot_table(df, values='D', index=['A', 'B'],\n",
       "...                     columns=['C'], aggfunc=np.sum)\n",
       ">>> table\n",
       "C        large  small\n",
       "A   B\n",
       "bar one      4      5\n",
       "    two      7      6\n",
       "foo one      4      1\n",
       "    two    NaN      6\n",
       "\n",
       "We can also fill missing values using the `fill_value` parameter.\n",
       "\n",
       ">>> table = pivot_table(df, values='D', index=['A', 'B'],\n",
       "...                     columns=['C'], aggfunc=np.sum, fill_value=0)\n",
       ">>> table\n",
       "C        large  small\n",
       "A   B\n",
       "bar one      4      5\n",
       "    two      7      6\n",
       "foo one      4      1\n",
       "    two      0      6\n",
       "\n",
       "The next example aggregates by taking the mean across multiple columns.\n",
       "\n",
       ">>> table = pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
       "...                     aggfunc={'D': np.mean,\n",
       "...                              'E': np.mean})\n",
       ">>> table\n",
       "                  D         E\n",
       "               mean      mean\n",
       "A   C\n",
       "bar large  5.500000  7.500000\n",
       "    small  5.500000  8.500000\n",
       "foo large  2.000000  4.500000\n",
       "    small  2.333333  4.333333\n",
       "\n",
       "We can also calculate multiple types of aggregations for any given\n",
       "value column.\n",
       "\n",
       ">>> table = pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
       "...                     aggfunc={'D': np.mean,\n",
       "...                              'E': [min, max, np.mean]})\n",
       ">>> table\n",
       "                  D   E\n",
       "               mean max      mean min\n",
       "A   C\n",
       "bar large  5.500000  9   7.500000   6\n",
       "    small  5.500000  9   8.500000   8\n",
       "foo large  2.000000  5   4.500000   4\n",
       "    small  2.333333  6   4.333333   2\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/pycon/lib/python3.7/site-packages/pandas/core/frame.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_households.pivot_table?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need are four things:\n",
    "1. What variable will become our `index`?\n",
    "2. What variable will become our `columns`?\n",
    "3. What variable will become our `values`?\n",
    "4. How will we aggregate our values?\n",
    "\n",
    "Pandas is going to grab each unique value in the variables you choose and use those as rows in your `.index` or separate columns in your `.columns`. The `values` variable should be _quantitative_ in this case (but it doesn't have to be, necessarily). `.pivot_table` will by default find the `mean` of your `values` variable for each cell in your new table, in this case we don't care about the `mean`, we want to `sum` up the total number of households."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the following:\n",
    "\n",
    "```python\n",
    "state_households.pivot_table(\n",
    "    index = '______',\n",
    "    columns = '______', \n",
    "    values = 'hhwt',\n",
    "    aggfunc = '___',\n",
    "    margins = True,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it to an appropriately named variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households_pivot_table = state_households.pivot_table(\n",
    "    index = '_____',\n",
    "    columns = '______',\n",
    "    ______ = '______',\n",
    "    ______ = '____',\n",
    "    _______ = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think the next step should be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
